behaviors:
  3DBall:
    trainer_type: all
    hyperparameters:
      batch_size: 64
      buffer_size: 12000
      learning_rate: 0.0003
      learning_rate_schedule: linear
    network_settings:
      normalize: true
      hidden_units: 128
      num_layers: 2
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 500000
    time_horizon: 1000
    summary_freq: 12000
    ppo:
      hyperparameters:
        batch_size: 64
        buffer_size: 12000
        learning_rate: 0.0003
        beta: 0.001
        epsilon: 0.2
        lambd: 0.99
        num_epoch: 3
        learning_rate_schedule: linear
      network_settings:
        normalize: true
        hidden_units: 128
        num_layers: 2
        vis_encode_type: simple
      reward_signals:
        extrinsic:
          gamma: 0.99
          strength: 1.0
    sac:
      hyperparameters:
        learning_rate: 0.0003
        learning_rate_schedule: constant
        batch_size: 64
        buffer_size: 200000
        buffer_init_steps: 0
        tau: 0.005
        steps_per_update: 10.0
        save_replay_buffer: false
        init_entcoef: 0.5
        reward_signal_steps_per_update: 10.0
      network_settings:
        normalize: true
        hidden_units: 64
        num_layers: 2
        vis_encode_type: simple
      reward_signals:
        extrinsic:
          gamma: 0.99
          strength: 1.0
    td3:
      hyperparameters:
        learning_rate: 0.0003
        learning_rate_schedule: constant
        batch_size: 128
        buffer_size: 50000
        buffer_init_steps: 0
        tau: 0.005
        steps_per_update: 1
        save_replay_buffer: false
        policy_delay: 2
        target_policy_noise: 0.2
        noise_clip: 0.5
        reward_signal_steps_per_update: 1
      network_settings:
        normalize: true
        hidden_units: 128
        num_layers: 2
        vis_encode_type: simple
      reward_signals:
        extrinsic:
          gamma: 0.99
          strength: 1.0
    tdsac:
      hyperparameters:
        learning_rate: 0.0003
        learning_rate_schedule: constant
        batch_size: 64
        buffer_size: 200000
        buffer_init_steps: 0
        tau: 0.005
        steps_per_update: 10.0
        save_replay_buffer: false
        init_entcoef: 0.5
        reward_signal_steps_per_update: 10.0
      network_settings:
        normalize: true
        hidden_units: 64
        num_layers: 2
        vis_encode_type: simple
      reward_signals:
        extrinsic:
          gamma: 0.99
          strength: 1.0
    tqc:
      hyperparameters:
        learning_rate: 0.0003
        learning_rate_schedule: constant
        batch_size: 64
        buffer_size: 200000
        buffer_init_steps: 0
        tau: 0.005
        steps_per_update: 10.0
        save_replay_buffer: false
        init_entcoef: 0.5
        reward_signal_steps_per_update: 10.0
        n_quantiles: 25
        n_to_drop: 2
      network_settings:
        normalize: true
        hidden_units: 64
        num_layers: 2
        vis_encode_type: simple
      reward_signals:
        extrinsic:
          gamma: 0.99
          strength: 1.0
    crossq:
      hyperparameters:
        learning_rate: 0.005
        learning_rate_schedule: constant
        batch_size: 8
        buffer_init_steps: 100
        buffer_size: 5000
        tau: 0.01
        policy_delay: 2
        target_policy_noise: 0.2
        noise_clip: 0.5
        reward_signal_steps_per_update: 1
      network_settings:
        normalize: true
        hidden_units: 16
        num_layers: 1
        vis_encode_type: simple
      reward_signals:
        extrinsic:
          gamma: 0.99
          strength: 1.0

